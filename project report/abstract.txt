# 1. Abstract

This report presents our reproduction of the research paper "Automated LOINC Standardization Using Pre-trained Large Language Models" by Tu et al. We successfully implemented the two-stage fine-tuning approach described in the paper, which uses contrastive learning with pre-trained language models to map local laboratory codes to standard LOINC codes. Despite using only 10% of the LOINC dataset due to computational constraints, our model achieved performance metrics closely aligned with those reported in the original paper. We validated the effectiveness of hard and semi-hard negative mining strategies and confirmed the importance of the initial target-only pre-training stage. Additionally, we implemented three extensions to address limitations mentioned in the original paper: hybrid feature integration for qualitative vs. quantitative distinction, similarity thresholding for no-match handling, and a comprehensive error analysis framework. Our reproduction effort demonstrates the robustness of the approach and its potential for practical application in healthcare settings with limited computational resources.

## 1.a. Video Presentation

[Link to video presentation](https://your-video-link-here)

## 1.b. GitHub Repository

[Link to GitHub repository](https://github.com/your-username/your-repo-name) 